---
title: "wrangle-data"
format: html
editor: visual
---

### Load in data

Here, I load in all the required packages to memory. Then, I read in all the files in a directory and store them in a list.

```{r load data}
#| include: false

library(tidyverse)
library(readxl)
library(sf)
library(ClimateNAr)
library(elevatr)
library(withr)
library(ncdf4)

# define the function to load all .xlsx files in a folder and put them in a list
load_xlsx_files <- function(directory) {
  # get the list of all .xlsx files in the specified directory
  file_list <- list.files(path = directory,
                          pattern = "*.xlsx",
                          full.names = TRUE)
  # extract file names without directory and extension, and clean them
  file_names <- str_replace_all(basename(file_list), 
                                "\\.[xX][lL][sS][xX]$", "")
  cleaned_names <- str_replace_all(file_names, "[^0-9]", "")
  
  # read each file and store the data in a list using purrr::map
  data_list <- purrr::map(file_list, read_excel)
  
  # assign cleaned names to the list elements
  names(data_list) <- cleaned_names
  
  # return the list of data frames
  return(data_list)
}

# run function to load in data
davis <- load_xlsx_files("../01_raw-data/davis/")
stebs <- load_xlsx_files("../01_raw-data/stebs/")

```

### Wrangle data frames

I wrangled the data matrix into observations by date (long format). I also added code to handle some of the idiosyncrasies in the spreadsheet format that caused errors when I tried to read it in.

```{r wrangle data}

# function to fill NA values with the most recent non-NA value in a row
fill_row <- function(row) {
  non_na_value <- NA
  for (i in 1:length(row)) {
    if (!is.na(row[i])) {
      non_na_value <- row[i]
    } else {
      row[i] <- non_na_value
    }
  }
  return(row)
}

# define the wrangle_data function for davis
wrangle_data_davis <- function(df, year) {
  # convert to df
  df <- df %>% as.data.frame()
  
  # remove the first row if there is a running total
  if (!is.na(df[3, 8]) && df[3, 8] == "Adults") {
    new_names <- ifelse(is.na(df[1, ]), paste0("...", seq_along(df[1, ])), df[1, ])
    new_names <- make.names(new_names, unique = TRUE)
    df <- setNames(df, new_names)
    df <- df %>% slice(-1)
  }
  
  # if night/month rows are flip-flopped
  if (df[1, 10] %in% c("N", "D")) {
    df[1, ] <- colnames(df) # colnames to first row
    df <- df %>% # remove day time data
      select(-which(str_detect(df[1, ], "D")))
    df[1, ] <- df[1, ] %>% # ... to NA
      str_replace(., "\\.\\.\\.", NA_character_) %>% as.list()
  }
  
  # apply the function only to the first row
  df[1, ] <- fill_row(as.vector(df[1, ]))
  
  # make a row for the dates
  date_row <- df %>%
    slice(c(1, 2)) %>%
    mutate_all(~ paste(., collapse = " "))
  
  # add it in
  df[1, ] <- date_row[1, ]
  
  # rename the columns as the first row
  df <- df %>%
    setNames(unlist(df[1, ]))
  
  # remove the last 4 columns
  df <- df[, -c((ncol(df) - 3):ncol(df))]
  
  # remove columns 3 through 6, 8, and 9
  df <- df %>%
    select(-3:-6, -8, -9)
  
  # define new column names for the species columns
  new_names <- c("hodges", "list", "verbatim_name")
  
  # small edits add up :)
  df <- df %>%
    # rename the species columns
    rename_with(~ new_names, c(1, 2, 3)) %>%
    # remove the first 2 rows using dplyr
    slice(-(1:2)) %>%
    # drop columns where "verbatim_name" is NA
    drop_na(verbatim_name) %>%
    # remove extra text
    filter(
      !verbatim_name == "Species:",
      !verbatim_name == "species (total)",
      !verbatim_name == "Individuals:",
      !verbatim_name == "Off:",
      !verbatim_name == "On:",
      !verbatim_name == "Temp., deg. F.:"
    ) %>%
    # remove periods from names
    rename_with(~ gsub("\\.", "", .), contains(".")) %>%
    # combine the first two columns into a single column
    mutate(hodges_list = ifelse(is.na(list), hodges, paste0(hodges, ".", list))) %>%
    # remove columns that were just used
    select(-c(hodges, list)) %>%
    # put hodges_list first
    select(hodges_list, everything()) %>%
    # pivot dates longer
    pivot_longer(
      cols = -c(hodges_list, verbatim_name),
      names_to = "date",
      values_to = "presence"
    ) %>%
    # remove NA rows (absences)
    mutate(presence = ifelse(is.na(presence), 0, 1)) %>%
    filter(presence != 0) %>%
    # remove presence column
    select(-presence) %>%
    # fix dates
    mutate(date = str_replace(date, "Sept", "Sep")) %>%
    mutate(date = as.Date(paste(date, year), format = "%b %d %Y"))
  
  return(df)
}

# define the wrangle_data function for stebs
wrangle_data_stebs <- function(df, year) {
  # convert to df
  df <- df %>% as.data.frame()
  
  # remove blank columns
df <- df %>%
  select(where(~ {
    if (is.numeric(.) || is.logical(.)) {
      !all(is.na(.) | . == 0 | . == FALSE)
    } else {
      TRUE  # Keep non-numeric and non-logical columns
    }
  }))
    
  # apply the function only to the first row
  df[1, ] <- fill_row(as.vector(df[1, ]))
  
  # make a row for the dates
  date_row <- df %>%
    slice(c(1, 2)) %>%
    mutate_all(~ paste(., collapse = " "))
  
  # add it in
  df[1, ] <- date_row[1, ]
  
  # remove daytime collection columns
  df <- df %>%
    select(-matches("D|NT|Trap|day"))
  
  # delete family column
  if (df[3,3] == "ERIOCRANIIDAE" | df[4,3] == "ERIOCRANIIDAE") {
    df <- df %>%
    select(-3)   
  }
  
  # remove columns 4 and 5
  df <- df %>%
    select(-4:-5)
  
  # remove the last 2 columns
  df <- df[, -c((ncol(df) - 1):ncol(df))]
  
  # rename the columns as the first row
  df <- df %>%
    setNames(unlist(df[1, ]))
  
  # define new column names for the species columns
  new_names <- c("hodges", "list", "verbatim_name")
  
  # small edits add up :)
  df <- df %>%
    # rename the species columns
    rename_with(~ new_names, c(1, 2, 3)) %>%
    # remove the first 2 rows using dplyr
    slice(-(1:2)) %>%
    # drop columns where "verbatim_name" is NA
    drop_na(verbatim_name) %>%
    # remove extra text
    filter(!verbatim_name == "Species:",
           !verbatim_name == "species (total)",
           !verbatim_name == "Individuals:",
           !verbatim_name == "Off:",
           !verbatim_name == "On:",
           !verbatim_name == "Temp., deg. F.:"
           ) %>%
    # remove periods from names
    rename_with(~ gsub("\\.", "", .), contains(".")) %>%
    # combine the first two columns into a single column
    mutate(hodges_list = ifelse(is.na(list), hodges, paste0(hodges, ".", list))) %>%
    # remove columns that were just used
    select(-c(hodges, list)) %>%
    # put hodges_list first
    select(hodges_list, everything()) %>%
    # pivot dates longer
    pivot_longer(
      cols = -c(hodges_list, verbatim_name),
      names_to = "date",
      values_to = "presence"
    ) %>%
    # remove NA rows (absences)
    mutate(presence = ifelse(is.na(presence), 0, 1)) %>%
    filter(presence != 0) %>%
    # remove presence column
    select(-presence) %>%
    # fix dates
    mutate(date = str_replace(date, "Sept", "Sep")) %>%
   mutate(date = as.Date(paste(date, year), format = "%b %d %Y"))
  
  return(df)
}

# wrangle data
davis_wrangled <- imap(davis, wrangle_data_davis) %>% 
  list_rbind() %>% drop_na(date)
stebs_wrangled <- imap(stebs, wrangle_data_stebs) %>% 
  list_rbind() %>% drop_na(date)

```

### 🚫 Link names via Hodges number

```{r}

# reshape the data frame
# old_names <- stebs_wrangled %>%
#   filter(!is.na(hodges_list)) %>%  # remove rows where hodges_list is NA
#   group_by(hodges_list) %>%
#   distinct(verbatim_name) %>%
#   mutate(occurrence = row_number()) %>%
#   pivot_wider(
#     id_cols = hodges_list,
#     names_from = occurrence,
#     values_from = verbatim_name,
#     names_prefix = "old_name"
#   )
# 
# # bring in John's list of preferred names
# preferred_names <- read_excel("../01_raw-data/Verbatim Stebbins Names.xlsx")
# 
# # concatenate columns 1 and 2 and removes blanks/extra columns
# # fill preferred_name column and then rename columns
# preferred_names <- preferred_names %>%
#   mutate(hodges_list = ifelse(is.na(`...2`), `...1`, paste0(`...1`, ".", `...2`))) %>%
#   filter(!is.na(`STEBSUM NAME`)) %>% # remove rows where STEBSUM NAME is NA
#   select(-c(`...1`, `...2`, `...3`, `...7`, `...8`)) %>%
#   mutate(preferred_name = ifelse(
#     !is.na(`PREFERRED NAME`), `PREFERRED NAME`, `STEBSUM NAME`)) %>%
#   select(hodges_list, preferred_name, -`VERBATIM NAME`, -`STEBSUM NAME`, -`PREFERRED NAME`)
#   
# # add preferred name column to old names
# preferred_names <- preferred_names %>%
#   right_join(old_names, by = "hodges_list")
# 
# # write CSV so I can manually check it
# write_csv(preferred_names, "../01_raw-data/preferred-names-unprocessed.csv")

```

### Match names to a backbone

First, I made a list of names, then I exported that list so that I could run a command line script to process the data and tie it back to the GBIF and iNat taxonomy backbones. Then, I created a column based on the sort scores so that I am able to identify which "species" need to be manually checked.

```{r name-match}

# create a function to match names to a backbone
get_names <- function(df, site) {
  # get species names
  taxa <- unique(df$verbatim_name)
  
  # construct file name string
  filename <- paste0("../01_raw-data/", site, "-names/", 
                     deparse(substitute(df)), ".txt")
  
  # construct file output string
  fileoutput <- paste0("../01_raw-data/", site, "-names/", 
                       deparse(substitute(df)), "-output.csv")
  
  # write to a text file for use with names verifier
  writeLines(taxa, filename)
  
  # parse names (prefer iNat (180) and GBIF (11))
  system(paste("gnverifier", filename, ">", fileoutput, " -s '11, 180'"))
  
  # read in matched names
  check_names <- read_csv(fileoutput)
  
  # select columns, rename, and join with obs data
  names_df <- check_names %>%
    select(SortScore, ScientificName, MatchedCanonical, 
           TaxonId, DataSourceTitle) %>%
    rename(sort_score = SortScore,
           verbatim_name = ScientificName,
           genus_species = MatchedCanonical,
           taxon_id = TaxonId,
           source = DataSourceTitle) %>%
    # create a column for bad matches or no matches
    mutate(manual_check = ifelse(sort_score < 9 | str_count(genus_species, "\\S+") < 2 | str_detect(verbatim_name, "\\?"), 1, 0)) %>%
    right_join(., df, join_by(verbatim_name))
  
  return(names_df)
}

# run function on davis names
davis_full <- get_names(davis_wrangled, "davis")
stebs_full <- get_names(stebs_wrangled, "stebs")

```

### Add checklist number

I joined the Moth Photographer's group checklist numbers to John's data.

```{r pohl-checklist}

# load in the checklist data
checklist <- read_excel("../01_raw-data/MPG-Taxa_20240311.xlsx") %>%
  rename(
    p_no = `P No`,
    genus_species = Genus_Species,
    common_name = `Common Name`,
    family = Family,
    genus = Genus,
    species = Species,
    synonymy = Synonymy
  ) %>%
select(p_no, MONA, genus_species, common_name, 
       family, genus, species, synonymy)

# update the taxonomy

# if genus_species from stebs_full is in the synonymy column (but not
# necesarily exactly equal), then replace genus_species from the
# data frame stebs_full with genus_species from the df checklist
stebs_full <- stebs_full %>%
  mutate(genus_species = case_when(
    sapply(genus_species, function(gs) {
      # Split the name into its components
      parts <- str_split(gs, " ")[[1]]
      # Create patterns for both binomial and trinomial matches
      patterns <- c(paste0("\\b", paste(parts[1:2], collapse = " "), "\\b"),
                    if (length(parts) > 2)
                      paste0("\\b", paste(parts[1:3], collapse = " "), "\\b")
                    else
                      NULL)
      # Check if any pattern matches
      any(sapply(patterns, function(pat)
        any(str_detect(
          checklist$synonymy, pat
        ))))
    }) ~
      sapply(genus_species, function(gs) {
        parts <- str_split(gs, " ")[[1]]
        patterns <- c(paste0("\\b", paste(parts[1:2], collapse = " "), "\\b"),
                      if (length(parts) > 2)
                        paste0("\\b", paste(parts[1:3], collapse = " "), "\\b")
                      else
                        NULL)
        for (pat in patterns) {
          match_index <- which(str_detect(checklist$synonymy, pat))
          if (length(match_index) > 0)
            return(checklist$genus_species[match_index[1]])
        }
        return(gs)
      }),
    TRUE ~ genus_species
  ))

# join the datasets together
davis_full <- left_join(davis_full, checklist)
stebs_full <- left_join(stebs_full, checklist)

```

### ⚠️ Add John's confidence levels

```{r john-species-confidence}



```

### Formatted preferred names

Double check that every observation has a preferred name.

```{r}

# load in list of names
preferred_names <- read_excel("../01_raw-data/Formatted Names.xlsx")

preferred_names <- preferred_names %>%
  # remove the 1st row
  slice(-1) %>%
  # remove the 4th column
  select(-4) %>%
  # combine the first and second columns
  mutate(hodges_list = ifelse(!is.na(`...2`), 
                              paste0(Hodges, ".", `...2`), 
                              Hodges)) %>%
  # remove columns used to make hodges_list
  select(hodges_list, everything(), -Hodges, -`...2`)

# vector of new names
col_names <- c(
  "hodges_list",
  "p_no",
  "verbatim_name",
  "preferred_name",
  "stebsum_name",
  "old_name1",
  "old_name2",
  "old_name3",
  "old_name4",
  "old_name5" ,
  "old_name6",
  "comments"
)

# rename
names(preferred_names) <- col_names

# get unique names from stebs data
unique_stebs <- stebs_wrangled %>% 
  select(verbatim_name) %>% 
  distinct()

# make a database with final columns and a list of old names
preferred_names_db <- preferred_names %>%
  select(hodges_list, p_no, preferred_name, comments) %>%
  mutate(old_names = map(1:nrow(.), function(i) {
    c(
      preferred_names$preferred_name[i],
      preferred_names$verbatim_name[i],
      preferred_names$stebsum_name[i],
      preferred_names$old_name1[i],
      preferred_names$old_name2[i],
      preferred_names$old_name3[i],
      preferred_names$old_name4[i],
      preferred_names$old_name5[i],
      preferred_names$old_name6[i]
    ) %>%
      discard(is.na)
  })) %>% distinct()

# unnest the old_names column so that each old name is in its own row
df_long <- preferred_names_db %>%
  unnest(old_names)

# join this long dataframe with the unique_names dataframe on old_name
unique_stebs_with_preferred <- unique_stebs %>%
  left_join(df_long, by = c("verbatim_name" = "old_names")) %>%
  rename("database_name" = "verbatim_name") %>%
  distinct() %>%
  select(hodges_list, p_no, everything())

write_csv(unique_stebs_with_preferred, "/Users/gracehorne/Downloads/database-matches.csv")

```

### Manual names check

This chunk provides exported lists of matched and unmatched names to be gone through by John and Grace.

```{r name-check}

# get list of unmatched names
davis_unmatched <- davis_full %>%
  filter(manual_check == 1) %>%
  distinct(verbatim_name)

# get list of matched names
davis_matched <- davis_full %>%
  filter(manual_check == 0) %>%
  distinct(verbatim_name)

# write unmatched names .csv
write_csv(davis_unmatched, "/Users/gracehorne/Library/CloudStorage/Box-Box/Meineke_Lab/Grace-folder/JAdB-moth-data/01_raw-data/davis-names/davis_unmatched.csv")

# write matched names .csv
write_csv(davis_matched, "/Users/gracehorne/Library/CloudStorage/Box-Box/Meineke_Lab/Grace-folder/JAdB-moth-data/01_raw-data/davis-names/davis_matched.csv")

# get list of unmatched names
stebs_unmatched <- stebs_full %>%
  filter(manual_check == 1) %>%
  distinct(verbatim_name)

# get list of matched names
stebs_matched <- stebs_full %>%
  filter(manual_check == 0) %>%
  distinct(verbatim_name)

# write unmatched names .csv
write_csv(stebs_unmatched, "/Users/gracehorne/Library/CloudStorage/Box-Box/Meineke_Lab/Grace-folder/JAdB-moth-data/01_raw-data/stebs-names/stebs_unmatched.csv")

# write matched names .csv
write_csv(stebs_matched, "/Users/gracehorne/Library/CloudStorage/Box-Box/Meineke_Lab/Grace-folder/JAdB-moth-data/01_raw-data/stebs-names/stebs_matched.csv")

```

### ClimateNA data

Here, I downloaded the data from ClimateNA programmatically. Because of the limits on queries one can ask of the database, I've opted to go with Terraclimate instead (below), for which no such limitations exist.

```{r climateNA}
#| eval: false

# # function to get elevation from a latitude and longitude
# get_elevation <- function(site, lon, lat) {
#   # create a single point
#   point <- st_point(c(lon, lat))
#   point_sf <- st_sfc(point, crs = 4326)
#   point_sf <- st_sf(geometry = point_sf)
#   
#   # get elevation
#   eldat <- get_elev_point(point_sf)
#   
#   # add columns for lat and lon and site plus rename elevation column
#   eldat$lon <- lon
#   eldat$lat <- lat
#   eldat$ID1 <- site
#   eldat$ID2 <- site
#   eldat$el <- eldat$elevation
#   
#   return(eldat)
# }
# 
# # get data for davis and stebs
# davis_el <- get_elevation(site = "davis", lat = 38.5569, lon = -121.78)
# stebs_el <- get_elevation(site = "stebs", lat = 38.51, lon = -122.0972)
# 
# # bind dataframes together
# site_info <- rbind(davis_el, stebs_el) %>% tibble() %>%
#   select(-elevation, -geometry, -elev_units) %>%
#   select(ID1, ID2, lat, lon, el)
# 
# test <- ClimateNAr::ClimateNA_API2(
#   ClimateBC_NA = "NA",
#   inputFile = site_info,
#   period = "Year_2022.ann",
#   MSY = "M"
# )
# 
# # empty list to be populated
# climate_data <- list()
# 
# # year range
# years <- 1989:2023
# 
# # Break the sequence into chunks of 5
# chunks <- split(years, ceiling(seq_along(years) / 5))
# 
# # get climate data for stebs and davis for year range
# for (year in chunks[[1]]) {
#   climate_data[[paste(year)]] <- ClimateNAr::ClimateNA_API2(
#   ClimateBC_NA = "NA",
#   inputFile = site_info,
#   period = paste0("Year_", year, ".ann"),
#   MSY = "M"
# )
# }

```

### Terraclimate data

I scraped the data from terraclimate for Davis and Cold Canyon locations between 1989 and 2023. I then put the data is a list called `dat` with sublists for Davis and Cold Canyon.

```{r terraclimate}

# make a df with dates
d1 <- as.Date("19580101", "%Y%m%d") # start date
d2 <- as.Date("20231231", "%Y%m%d") # end date

# fill in dates between
dat <- format(seq(d1, d2, by = "month"), "%m %Y") %>% 
  as_tibble() %>%
  separate(value, into = c("month", "year"), sep = " ")

# list for davis and stebs with all dates
dat <- list("davis" = dat, "stebs" = dat)

# for loop for both sites to get data
for (site in c("davis", "stebs")) {
  
  temp_dat = tibble(.rows = 792) # must equal number of months in dataset
  
  if (site == "davis") {
    x = c(-121.78, 38.5569) # Davis long, lat
  } else if (site == "stebs") {
    x = c(-122.0972, 38.51) # Stebs long, lat
  }
  
  # gather all variables of interest
for (var in c("tmax", "tmin", "ppt")) {
  baseurlagg <-
    paste0(
      paste0(
        "http://thredds.northwestknowledge.net:8080/thredds/dodsC/agg_terraclimate_",
        var
      ),
      "_1958_CurrentYear_GLOBE.nc"
    )
  
  nc <- nc_open(baseurlagg)
  lon <- ncvar_get(nc, "lon")
  lat <- ncvar_get(nc, "lat")
  flat = match(abs(lat - x[2]) < 1 / 48, 1)
  latindex = which(flat %in% 1)
  flon = match(abs(lon - x[1]) < 1 / 48, 1)
  lonindex = which(flon %in% 1)
  start <- c(lonindex, latindex, 1)
  count <- c(1, 1, -1)
  
  # read in the full period of record using aggregated files
  data = as.numeric(ncvar_get(nc, varid = var, start = start, count)) %>%
    as_tibble_col(., column_name = var)
  temp_dat = temp_dat %>% add_column(data)
  
}
  temp_dat = temp_dat %>% mutate(dataset = site)
  dat[[site]] = cbind(temp_dat, dat[[site]])
}

TerraClimate <- dat %>% map_dfr(~ as_tibble(.)) %>% filter(year >= 1989 & year < 2024) %>%
  mutate(source = "terraclimate",
         month = as.numeric(month),
         year = as.numeric(year))

```

### Format seasonal weather data

Here, I summarize the weather data by season instead of month:

-   First, I need to make a new column for `water_year`. For example, water year 1998 includes September through December of calendar year 1997

-   Next, I need to group variables by season. Fall (suffix = `_at`) = months 9, 10, 11, winter (`_wt`) = 12, 1, 2, spring (`_sp`) = 3, 4, 5, and summer (`_sm`) = 6, 7, 8.

```{r seasonal-weather}

# function to assign season based on month
get_season <- function(month) {
  case_when(
    month %in% c(9, 10, 11) ~ "at",
    month %in% c(12, 1, 2) ~ "wt",
    month %in% c(3, 4, 5) ~ "sp",
    month %in% c(6, 7, 8) ~ "sm"
  )
}

# create water_year and season columns, remove month column
# set water year column (September to August)
TerraClimate <- TerraClimate %>%
  mutate(
    water_year = ifelse(month %in% c(9, 10, 11, 12), year - 1, year),
    season = get_season(month)
  ) %>%
  select(-month)

# weather data per year
weather <- TerraClimate %>%
  group_by(season, dataset, year) %>%
  summarise(
    tmin = mean(tmin, na.rm = TRUE),
    tmax = mean(tmax, na.rm = TRUE),
    ppt = sum(ppt, na.rm = TRUE)
  )

# join weather data to observation data
stebs_full <- stebs_full %>%
  mutate(month = month(date), 
         year = year(date), 
         season = get_season(month)) %>%
  left_join(weather %>% filter(dataset == "stebs"), by = c("season", "year"))

davis_full <- davis_full %>%
  mutate(month = month(date), 
         year = year(date), 
         season = get_season(month)) %>%
  left_join(weather %>% filter(dataset == "davis"), by = c("season", "year"))
  
```

### Calculate adjusted FDPs

```{r fdps}

# write a function to calculate fractional day positives
calculate_FDP <- function(data) {
    # convert date to year and day of year (DOY)
  data <- data %>%
    mutate(year = year(date), DOY = yday(date))
  
  # calculate day_positives and collection_events
  day_positives <- data %>%
    group_by(genus_species, year) %>%
    summarise(day_positives = n(), .groups = 'drop')
  
  collection_events <- data %>%
    group_by(year) %>%
    summarise(collection_events = n_distinct(date), .groups = 'drop')
  
  # calculate flight_min and flight_max
  flight_window <- data %>%
    group_by(genus_species) %>%
    summarise(
      flight_min = min(DOY),
      flight_max = max(DOY),
      .groups = 'drop'
    )
  
  # merge flight window with original data
  data <- data %>%
    left_join(flight_window, by = "genus_species")
  
  # initialize dataframe for adj_collection_events
  adj_collection_events <- data.frame(
    genus_species = character(),
    year = integer(),
    adj_collection_events = integer(),
    stringsAsFactors = FALSE
  )
  
  # calculate adj_collection_events using nested for loop with indexing
  unique_species <- unique(data$genus_species) %>% na.omit()
  unique_years <- unique(data$year) %>% na.omit()
  
  for (i in seq_along(unique_species)) {
    species <- unique_species[i]
    species_data <- data %>% filter(genus_species == species)
    flight_min <- unique(species_data$flight_min)
    flight_max <- unique(species_data$flight_max)
    
    for (j in seq_along(unique_years)) {
      annum <- unique_years[j]
      year_data <- data %>% filter(year == annum)
      distinct_dates <- unique(year_data$date)
      tally <- sum(yday(distinct_dates) >= flight_min &
                     yday(distinct_dates) <= flight_max)
      
      adj_collection_events <- rbind(
        adj_collection_events,
        data.frame(
          genus_species = species,
          year = annum,
          adj_collection_events = tally
        )
      )
    }
  }
  
  # combine all results
  result <- day_positives %>%
    left_join(collection_events, by = "year") %>%
    mutate(day_negatives = collection_events - day_positives) %>%
    left_join(flight_window, by = "genus_species") %>%
    left_join(adj_collection_events, by = c("genus_species", "year"))
  
  data <- left_join(data, result)
  
  return(data)
}

# list of dataframes to iterate over
data_list <- list(
  stebs = stebs_full,
  davis = davis_full
)

# apply the function to each dataframe in the list
results <- map(data_list, calculate_FDP)

# flatten the list by appending data frames and create a new column based on list names
full_data <- bind_rows(
  map2(results, names(results), ~ {
    .x %>%
      mutate(dataset = .y)
  })
)

```

### Add in pest, fire, and trail data

At this juncture, I only want to know if a species is a pest or not. So, I will create a list of all species in the pest data frame. If a binomial is in it, then it will receive a 1 in the column `any_pest` if not it will receive a 0. Trail and fire need only to be joined to the Cold Canyon data.

```{r predictors}

# get fire years 
fire_predictor <- read_csv("../03_processed-data/predictors/fire_predictor.csv")

# get trail years
trail_predictor <- read_csv("../03_processed-data/predictors/trail_predictor.csv")

# join fire and trail predictors to stebs data
# filter for dataset == "stebs"
stebs_data <- full_data %>%
  filter(dataset == "stebs")

# perform the joins only for the filtered data
stebs_data <- stebs_data %>%
  left_join(fire_predictor) %>%
  left_join(trail_predictor)  

# combine with the original data, keeping the rows where dataset != "stebs"
full_data <- full_data %>%
  filter(dataset != "stebs") %>%
  bind_rows(stebs_data)

# load pest data
pest_predictor <- read_csv("../03_processed-data/predictors/pest_status.csv")

# reshape the dataframe to long format
long_pest_predictor <- pest_predictor %>%
  pivot_longer(cols = everything(), names_to = "crop", values_to = "presence")

# get unique pest species
unique_pests <- unique(long_pest_predictor[[2]])  # The first column name might vary

# add pest status to full df
full_data  <- full_data %>%
  mutate(any_pest = ifelse(genus_species %in% unique_pests & !is.na(genus_species), 1, 0))

```
